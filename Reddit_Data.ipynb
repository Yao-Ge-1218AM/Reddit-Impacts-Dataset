{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-fgIcvOkGxk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "path = \"/content/converted_qui9.tsv\"\n",
        "path1 = \"/content/converted_qui9_new.tsv\"\n",
        "\n",
        "with open(path,'r') as f:\n",
        "  with open(path1,'w') as wf:\n",
        "    #train=pd.read_csv(f, sep='\\t')\n",
        "    #print(train)\n",
        "    text = f.readlines()\n",
        "    #print(text)\n",
        "    for line in text:\n",
        "      if(line.startswith(\"#\")==0 and line!=\"\\n\"):\n",
        "        #print(line)\n",
        "        wf.write(line)\n",
        "      else:\n",
        "        wf.write(\"\\n\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/converted_qui9_new.tsv\"\n",
        "path1 = \"/content/converted_qui9_new1.tsv\"\n",
        "\n",
        "with open(path,'r') as f:\n",
        "  with open(path1,'w') as wf:\n",
        "    #train=pd.read_csv(f, sep='\\t')\n",
        "    #print(train)\n",
        "    text = f.readlines()\n",
        "    #print(text)\n",
        "    for line in text:\n",
        "      if(line!=\"\\n\"):\n",
        "        new_line = line.strip(\"\\n\").split(\"\\t\")\n",
        "        #print(new_line)\n",
        "        if(new_line[3]!=\"_\"):\n",
        "          wf.write(new_line[2] + \" \" + new_line[3] + \"\\n\")\n",
        "        elif(new_line[3]==\"_\"):\n",
        "          wf.write(new_line[2] + \" \" + \"O\" + \"\\n\")\n",
        "      else:\n",
        "        wf.write(\"\\n\")"
      ],
      "metadata": {
        "id": "U-CMqoS4bvTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "下载下来后\n",
        "\n",
        "删除掉多余的\\n\n",
        "\n",
        "删掉- O\n",
        "\n",
        "删掉< O 和 > O\n",
        "\n",
        "submission前面也要多空一行\n",
        "\n",
        ". O\\n 改成多空一行，这样的情况可能导致...也会被分开，不过问题不大\n",
        "\n",
        "有时候会有奇怪的一长串字母，可能是乱码或者链接，可以删除"
      ],
      "metadata": {
        "id": "9jgNaJYHnA70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/final0.zip"
      ],
      "metadata": {
        "id": "yPpmWBHsnD_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "之前留下的错误，把token和entity之间改成\\t，然后entity的拼写把空格改成_"
      ],
      "metadata": {
        "id": "luXlzFT7ru-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "\n",
        "path = \"/content/final0/\"\n",
        "path1 = \"/content/final1/\"\n",
        "\n",
        "for file in os.listdir(path):\n",
        "  #print(file[:6])\n",
        "  with open(path + \"/\" + file, \"r\") as f:\n",
        "    with open(path1 + \"/\" + file, \"a\") as wf:\n",
        "      #train=pd.read_csv(f, sep=\"\\t\")\n",
        "      #print(train.head())\n",
        "      text = f.readlines()\n",
        "      for line in text:\n",
        "        if(line!=\"\\n\"):\n",
        "          new_line = line.strip(\"\\n\").split(\" \")\n",
        "          #print(new_line, len(new_line))\n",
        "          if(len(new_line)>2):\n",
        "            wf.write(new_line[0] + \"\\t\")\n",
        "            for j in range(2,len(new_line)):\n",
        "              wf.write(new_line[j] + \"_\")\n",
        "            wf.write(\"\\n\")\n",
        "          elif(len(new_line)==2):\n",
        "            wf.write(new_line[0] + \"\\t\" + new_line[1] + \"\\n\")\n",
        "          #wf.write(line)\n",
        "        else:\n",
        "          wf.write(\"\\n\")"
      ],
      "metadata": {
        "id": "pfgkWNQ0hBZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/final1"
      ],
      "metadata": {
        "id": "LAUNancVljaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/final1/"
      ],
      "metadata": {
        "id": "sRvi9ACFloW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip /content/final1.zip /content/final1/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHAeJnPdr9HK",
        "outputId": "92dc3df1-c01c-4847-c27d-7e10d8e03b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/final1/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "有多少个entity"
      ],
      "metadata": {
        "id": "YJGLBco0GulH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/train-reddit.txt\"\n",
        "entity = set()\n",
        "\n",
        "with open(path,'r') as f:\n",
        "  text = f.readlines()\n",
        "  for line in text:\n",
        "    if(line!=\"\\n\"):\n",
        "      new_line = line.strip(\"\\n\").split(\" \")\n",
        "      #print(new_line)\n",
        "      if(new_line[1].startswith(\"B-\")):\n",
        "        entity.add(new_line[1])"
      ],
      "metadata": {
        "id": "mtPSKIM1GwnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(entity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfWl-ZI3HTMp",
        "outputId": "5fb16ecc-d0b2-4c7a-eb09-7b3e9e927659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-Ethnicity', 'B-Education', 'B-Location', 'B-NMPDU:', 'B-IDU:', 'B-Medical', 'B-MI:', 'B-Household', 'B-Tobacco', 'B-Medicine', 'B-Occupation', 'B-Abuse/Misuse', 'B-Age', 'B-null', 'B-Alcohol:', 'B-Country', 'B-Illegal', 'B-Gender', 'B-Vape', 'B-Marital', 'B-Advice', 'B-Supplements', 'B-Nonmedical'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/dev-reddit.txt\"\n",
        "entity_dev = set()\n",
        "\n",
        "with open(path,'r') as f:\n",
        "  text = f.readlines()\n",
        "  for line in text:\n",
        "    if(line!=\"\\n\"):\n",
        "      new_line = line.strip(\"\\n\").split(\" \")\n",
        "      #print(new_line)\n",
        "      if(new_line[1].startswith(\"B-\")):\n",
        "        entity_dev.add(new_line[1])"
      ],
      "metadata": {
        "id": "XigYZa2tHf3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(entity_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5niSD0whHklF",
        "outputId": "47dc34e3-b385-4d74-b23a-19f8803ef7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-MI:', 'B-Gender', 'B-Country', 'B-Location', 'B-Tobacco', 'B-Occupation', 'B-NMPDU:', 'B-IDU:', 'B-Age', 'B-Abuse/Misuse', 'B-Advice', 'B-null', 'B-Nonmedical', 'B-Medicine', 'B-Alcohol:', 'B-Illegal'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/test-reddit.txt\"\n",
        "entity_test = set()\n",
        "\n",
        "with open(path,'r') as f:\n",
        "  text = f.readlines()\n",
        "  for line in text:\n",
        "    if(line!=\"\\n\"):\n",
        "      new_line = line.strip(\"\\n\").split(\" \")\n",
        "      #print(new_line)\n",
        "      if(new_line[1].startswith(\"B-\")):\n",
        "        entity_test.add(new_line[1])"
      ],
      "metadata": {
        "id": "BsmbBonWHqwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(entity_test)"
      ],
      "metadata": {
        "id": "-3PAUcIaHtia",
        "outputId": "4e0f5000-5f31-4df4-fbc5-9fb20bf635b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-Ethnicity', 'B-Education', 'B-Location', 'B-NMPDU:', 'B-IDU:', 'B-Medical', 'B-MI:', 'B-Household', 'B-Medicine', 'B-Age', 'B-Abuse/Misuse', 'B-Alcohol:', 'B-Illegal', 'B-Notes', 'B-Gender', 'B-Vape', 'B-Marital', 'B-Advice', 'B-Nonmedical'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "只保留clinical impact和social impact"
      ],
      "metadata": {
        "id": "wRV0dj-wsGam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/test-reddit.txt\"\n",
        "path1 = \"/content/test-reddit-impact.txt\"\n",
        "\n",
        "with open(path,'r') as f:\n",
        "  with open(path1,'w') as wf:\n",
        "    #train=pd.read_csv(f, sep='\\t')\n",
        "    #print(train)\n",
        "    text = f.readlines()\n",
        "    #print(text)\n",
        "    for line in text:\n",
        "      if(line!=\"\\n\"):\n",
        "        new_line = line.strip(\"\\n\").split(\" \")\n",
        "        #print(new_line)\n",
        "        if(new_line[1]!=\"B-Abuse/Misuse_Clinical_Impacts\" and new_line[1]!=\"B-Abuse/Misuse_Social_Impacts\"\n",
        "           and new_line[1]!=\"I-Abuse/Misuse_Clinical_Impacts\" and new_line[1]!=\"I-Abuse/Misuse_Social_Impacts\"):\n",
        "          wf.write(new_line[0] + \" \" + \"O\" + \"\\n\")\n",
        "        else:\n",
        "          wf.write(line)\n",
        "      else:\n",
        "        wf.write(\"\\n\")"
      ],
      "metadata": {
        "id": "M2viaSYZsLuH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}